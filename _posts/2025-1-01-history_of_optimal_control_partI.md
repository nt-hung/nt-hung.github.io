---
title: 'The history of optimal control - Part I'
date: 2025-1-01
permalink: /posts/2020/11/history_optimal_control_part_I/
excerpt_separator: <!--more-->
usemath: true
tags:
  - Scientific story
  - Mathematic
  - Control 
---

NhÃ¢n dá»‹p chuáº©n bá»‹ tÃ i liá»‡u cho má»™t seminar vá» optimal control á»©ng dá»¥ng trong autonomous robotic vehicles, xin chia sáº» cÃ¹ng má»i ngÆ°á»i má»™t chÃºt hiá»ƒu biáº¿t mang tÃ­nh lá»‹ch sá»­, hy vá»ng thÃº vá»‹ vÃ  há»¯u Ã­ch cho ai muá»‘n tham kháº£o má»™t gÃ³c nhÃ¬n tá»•ng quan vá» topic nÃ y.

<!--more-->

<p align="center">
<img src="/images/posts/optimal_control/map_part_I.jpg" width="700">
</p>


## Pháº§n 1: Thá»i Hiá»‡n Äáº¡i (1950s - nay)

Nhá»¯ng ngÆ°á»i quan tÃ¢m Ä‘áº¿n lá»‹ch sá»­ ngÃ nh Ä‘iá»u khiá»ƒn cÃ³ láº½ Ä‘á»u Ä‘á»“ng Ã½ ráº±ng optimal control ra Ä‘á»i vÃ o tháº­p niÃªn 1950, thÃºc Ä‘áº©y máº¡nh máº» má»™t pháº§n bá»Ÿi cuá»™c cáº¡nh tranh giá»¯a hai Ã´ng lá»›n LiÃªn XÃ´ vÃ  Má»¹ sau Tháº¿ Chiáº¿n thá»© hai. VÃ o thá»i Ä‘Ã³, cÃ¡c bÃ i toÃ¡n Ä‘iá»u khiá»ƒn tá»‘i Æ°u trong lÄ©nh vá»±c quÃ¢n sá»± Ä‘Æ°á»£c xem lÃ  â€œhotâ€, bao gá»“m Ä‘iá»u khiá»ƒn tÃªn lá»­a, tá»‘i Æ°u hÃ³a váº­n táº£i, tá»‘i Æ°u quáº£n lÃ½ váº­t tÆ°, hay tá»‘i Æ°u Ä‘iá»u phá»‘i lá»±c lÆ°á»£ng, vv. Cháº³ng háº¡n, vá»›i tÃªn lá»­a, cÃ¢u há»i Ä‘áº·t ra lÃ : lÃ m sao Ä‘á»ƒ Ä‘iá»u khiá»ƒn nÃ³ tiáº¿t kiá»‡m nhiÃªn liá»‡u nháº¥t, Ä‘i Ä‘Æ°á»£c xa nháº¥t, hay Ä‘áº¡t Ä‘Æ°á»£c váº­n tá»‘c cuá»‘i (terminal velocity) lá»›n nháº¥t.
PhÃ­a Má»¹: Bellman giá»›i thiá»‡u Dynamic Programming (DP) vÃ o nÄƒm 1953. DP dá»±a trÃªn NguyÃªn lÃ½ Tá»‘i Æ°u (Principle of Optimality), chia nhá» bÃ i toÃ¡n tá»‘i Æ°u tá»•ng thá»ƒ phá»©c táº¡p thÃ nh cÃ¡c bÃ i toÃ¡n con Ä‘á»ƒ giáº£i quyáº¿t. Trong khi Ä‘Ã³ phÃ­a LiÃªn XÃ´: Pontryagin phÃ¡t triá»ƒn NguyÃªn lÃ½ Cá»±c Ä‘áº¡i (Pontryaginâ€™s Maximum Principle - PMP), cÃ´ng bá»‘ vÃ o nÄƒm 1957. PMP xÃ¢y dá»±ng trÃªn ná»n táº£ng phÆ°Æ¡ng phÃ¡p biáº¿n phÃ¢n (Calculus of Variations), cung cáº¥p Ä‘iá»u kiá»‡n cáº§n cho bÃ i toÃ¡n Ä‘iá»u khiá»ƒn tá»‘i Æ°u, cÃ³ thá»ƒ Ã¡p dá»¥ng khÃ´ng chá»‰ cho há»‡ phi tuyáº¿n mÃ  cÃ²n rÃ ng buá»™c á»Ÿ ngÃµ vÃ o cá»§a há»‡ thá»‘ng Ä‘iá»u khiá»ƒn. ThÃº vá»‹ lÃ  Pontryagin lÃ m viá»‡c trong Ä‘iá»u kiá»‡n bá»‹ mÃ¹ tá»« nÄƒm 14 tuá»•i, nÃªn cÅ©ng khÃ´ng hiá»ƒu lÃ  cá»¥ nghiÃªn cá»©u báº±ng cÃ¡ch nÃ o mÃ  ra lÃ½ thuyáº¿t hay tháº¿. NhÆ°ng cháº¯c cháº¯n do bá»‹ mÃ¹ cá»¥ sáº½ táº­p trung hÆ¡n vÃ¬ khÃ´ng tháº¥y Ä‘Æ°á»£c nhiá»u cÃ¡m dá»— nhÆ° anh em chÃºng ta ğŸ˜ƒ.

Cáº£ DP vÃ  PMP Ä‘á»u Ä‘Æ°a ra cÃ¡c Ä‘iá»u kiá»‡n tá»‘i Æ°u cho má»™t bÃ i toÃ¡n Ä‘iá»u khiá»ƒn tá»‘i Æ°u tá»•ng quÃ¡t. Tuy nhiÃªn, háº¡n cháº¿ lá»›n lÃºc báº¥y giá» lÃ  khÃ´ng pháº£i lÃºc nÃ o cÅ©ng tÃ¬m Ä‘Æ°á»£c luáº­t Ä‘iá»u khiá»ƒn giáº£i tÃ­ch (analytical control law). Vá»›i DP, váº¥n Ä‘á» cÃ²n náº±m á»Ÿ "lá»i nguyá»n chiá»u (curse of dimensionality)", trong khi PMP Ä‘Ã²i há»i giáº£i há»‡ phÆ°Æ¡ng trÃ¬nh vi phÃ¢n biÃªn phá»©c táº¡p. Thá»i Ä‘Ã³, mÃ¡y tÃ­nh cÃ²n yáº¿u, vÃ  solver/software vÃ  cÃ¡c phÆ°Æ¡ng phÃ¡p sá»‘ chÆ°a phÃ¡t triá»ƒn, nÃªn viá»‡c triá»ƒn khai thá»±c tiá»…n gáº·p nhiá»u khÃ³ khÄƒn. Do Ä‘Ã³ máº¥y nhÃ  Ä‘iá»u khiá»ƒn há»c má»›i nghÄ© láº¡i thay vÃ¬ cá»‘ gáº¯ng giáº£i bÃ i toÃ¡n Ä‘iá»u khiá»ƒn tá»‘i Æ°u tá»•ng quÃ¡t thÃ¬ liá»‡u xem xÃ©t láº¡i cÃ¡c há»‡ thá»‘ng Ä‘Æ¡n giáº£n nhÆ° tuyáº¿n tÃ­nh, khÃ´ng rÃ ng buá»™c á»Ÿ input hay state thÃ¬ liá»‡u cÃ³ thá»ƒ dá»… giáº£i hÆ¡n khÃ´ng ?

Tháº­p niÃªn 1960 Ä‘Ã¡nh dáº¥u má»™t bÆ°á»›c tiáº¿n lá»›n trong Ä‘iá»u khiá»ƒn tá»‘i Æ°u vá»›i sá»± ra Ä‘á»i cá»§a Linear Quadratic Regulator (LQR) do Kalman giá»›i thiá»‡u vÃ o nÄƒm 1960 [1]. LQR giáº£i quyáº¿t bÃ i toÃ¡n Ä‘iá»u khiá»ƒn tá»‘i Æ°u cho há»‡ tuyáº¿n tÃ­nh, quadratic cost, khÃ´ng cÃ³ rÃ ng buá»™c trÃªn inputs vÃ  states. Nhá» Ä‘Ã³, dá»±a trÃªn phÆ°Æ¡ng trÃ¬nh Hamilton-Jacobi (HJ), Kalman xÃ¢y dá»±ng Ä‘Æ°á»£c luáº­t Ä‘iá»u khiá»ƒn tá»‘i Æ°u dÆ°á»›i dáº¡ng pháº£n há»“i tuyáº¿n tÃ­nh: u=âˆ’Kx, vá»›i K cÃ³ thá»ƒ tÃ­nh Ä‘Æ°á»£c tá»« nghiá»‡m cá»§a phÆ°Æ¡ng trÃ¬nh Riccati. CÅ©ng trong nÄƒm 1960, Kalman cÃ´ng bá»‘ bá»™ lá»c Kalman [2], mÃ  cháº¯c ai trong chÃºng ta cÅ©ng Ä‘Ã£ tá»«ng thiáº¿t káº¿ Ä‘á»ƒ Æ°á»›c lÆ°á»£ng tráº¡ng thÃ¡i cá»§a há»‡ thá»‘ng (state estimation). Sá»± káº¿t há»£p giá»¯a LQR vÃ  Bá»™ lá»c Kalman táº¡o nÃªn Linear Quadratic Gaussian (LQG) táº¡o nÃªn cÃ´ng cá»¥ máº¡nh máº½ cho Ä‘iá»u khiá»ƒn vÃ  Æ°á»›c lÆ°á»£ng tráº¡ng thÃ¡i, do dá»… thá»±c thi, vÃ  ngay láº­p tá»©c á»©ng dá»¥ng nhiá»u trong aerospace industry.

Tuy nhiÃªn LQG gáº·p váº¥n Ä‘á» vá»›i model uncertainty (eg. parameter uncertainty, model structure uncertainty hay disturbance khÃ´ng pháº£i Gaussian). Äá»ƒ chá»©ng minh Ä‘iá»u nÃ y nÄƒm 1978, John Doyle cÃ´ng bá»‘ má»™t bÃ i bÃ¡o vá»›i pháº§n tÃ³m táº¯t chá»‰ vá»n váº¹n má»™t tá»« â€œNoneâ€ [4], chá»‰ ra ráº±ng LQG khÃ´ng Ä‘áº£m báº£o biÃªn Ä‘á»™ á»•n Ä‘á»‹nh (gain and phase margin), tá»©c lÃ  cÃ³ nhá»¯ng há»‡ thá»‘ng chá»‰ cáº§n cÃ³ chÃºt khÃ¡c biá»‡t giá»¯a mÃ´ hÃ¬nh thiáº¿t káº¿ LQG vÃ  há»‡ thá»‘ng thá»±c thÃ¬ khi triá»ƒn khai há»‡ thá»‘ng cÃ³ thá»ƒ máº¥t á»•n Ä‘á»‹nh. PhÃ¡t hiá»‡n nÃ y Ä‘áº·t ra váº¥n Ä‘á» Ä‘au Ä‘áº§u cho cÃ¡c nhÃ  lÃ m Ä‘iá»u khiá»ƒn, má»Ÿ ra má»™t hÆ°á»›ng nghiÃªn cá»©u má»›i gá»i lÃ  robust control, kÃ©o dÃ i cho Ä‘áº¿n tháº­p niÃªn 90s.
George Zames Ä‘Æ°á»£c xem lÃ  ngÆ°á»i tiÃªn phong trong robust control, xÃ¢y dá»±ng bÃ i toÃ¡n H_inf, Ä‘Ã¢u Ä‘Ã³ tá»« nÄƒm 1981. H_inf khÃ¡c vá»›i LQR á»Ÿ chá»— trong khi LQR táº­p trung tá»‘i Æ°u hÃ³a performance (vÃ­ dá»¥ minimize tracking error hay input expense), thÃ¬ H_inf táº­p trung giáº£m thiá»ƒu tá»‘i Ä‘a áº£nh hÆ°á»Ÿng cá»§a exogenous disturbance input (vÃ­ dá»¥ nhÆ° nhiá»…u cá»§a actuator, cá»§a sensor â€¦) lÃªn performance (má»i ngÆ°á»i cÃ³ thá»ƒ xem hÃ¬nh Ä‘á»ƒ hÃ¬nh dung rÃµ hÆ¡n). Tuy nhiÃªn mÃ£i Ä‘áº¿n nÄƒm 1988, láº¡i lÃ  John Doyle ngÆ°á»i chá»‰ ra báº¥t cáº­p LQR cÃ´ng bá»‘ giáº£i phÃ¡p mang tÃ­nh Ä‘á»™t phÃ¡ [5] cho bÃ i toÃ¡n H_inf. PhÆ°Æ¡ng phÃ¡p cá»§a John Doyle dá»±a trÃªn mÃ´ hÃ¬nh tráº¡ng thÃ¡i state-space nÃªn tá»•ng quÃ¡t vÃ  sau nÃ y Ä‘Æ°á»£c tÃ­ch há»£p trong Robust Control Toolbox cá»§a MATLAB. Robust Control Toolbox cÃ²n tÃ­ch há»£p má»™t solution khÃ¡c cho H_inf dÃ¹ng phÆ°Æ¡ng phÃ¡p LMI, phÃ¡t triá»ƒn nhiá»u nÄƒm sau Ä‘Ã³ bá»Ÿi Pierre Apkarian [7], 1994.

Bá»™ Ä‘iá»u khiá»ƒn Hâˆ cá»§a Doyle cÃ³ dáº¡ng má»™t state-space model cÃ³ báº­c báº±ng tá»•ng báº­c cá»§a há»‡ thá»‘ng Ä‘Æ°á»£c Ä‘iá»u khiá»ƒn vÃ  báº­c cá»§a cÃ¡c trá»ng sá»‘ thÃªm vÃ o trong quÃ¡ trÃ¬nh thiáº¿t káº¿ nÃªn thÆ°á»ng lÃ  cÃ³ báº­c cao. VÃ¬ tÃ­nh cháº¥t nÃ y nÃ³ cÃ²n Ä‘Æ°á»£c gá»i lÃ  full-order H_inf. Má»™t sá»‘ tÃ i liá»‡u khÃ¡c bá»™ Ä‘iá»u khiá»ƒn H_inf nÃ y cÃ²n Ä‘Æ°á»£c gá»i unstructured H_inf vÃ¬ mÃ¬nh khÃ´ng biáº¿t cáº¥u trÃºc bÃªn trong bá»™ Ä‘iá»u khiá»ƒn lÃ  nhÆ° tháº¿ nÃ o cáº£. Hai Ä‘iá»u nÃ y khÃ´ng pháº£i tá»‘t láº¯m trong thá»±c táº¿ vÃ¬ náº¿u bá»™ Ä‘iá»u khiá»ƒn cÃ³ báº­c cao sáº½ lÃ m tÄƒng thá»i gian tÃ­nh toÃ¡n vÃ  vÃ¬ nÃ³ khÃ´ng cÃ³ cáº¥u trÃºc nÃªn ráº¥t khÃ³ tunning. Do Ä‘Ã³ bÃ i toÃ¡n má»›i Ä‘áº·t ra cho H_inf lÃ  liá»‡u cÃ³ thá»ƒ thiáº¿t káº¿ má»™t bá»™ Ä‘iá»u khiá»ƒn Ä‘Æ¡n giáº£n, cÃ³ cáº¥u trÃºc rÃµ rÃ ng nhÆ° PID mÃ  váº«n Ä‘áº£m báº£o robust Ä‘Æ°á»£c hay khÃ´ng ?

Pierre Apkarian vÃ  cá»™ng sá»± theo Ä‘uá»•i bÃ i toÃ¡n nÃ y vÃ  Ä‘áº¿n nÄƒm 2017 tÃ³m táº¯t trong má»™t bÃ i bÃ¡o cÃ³ tÃªn ráº¥t kÃªu â€œThe Hâˆ Control Problem is Solvedâ€ [6]. Ã tÆ°á»Ÿng cá»§a Pierre lÃ  fix cáº¥u trÃºc cá»§a bá»™ Ä‘iá»u khiá»ƒn trÆ°á»›c, vÃ­ dá»¥ nhÆ° PID cháº³ng háº¡n rá»“i tÃ¬m giáº£i phÃ¡p Ä‘á»ƒ tune cÃ¡c há»‡ sá»‘ cá»§a bá»™ Ä‘iá»u khiá»ƒn (Kp, Ki..) sau, sao cho nÃ³ váº«n robust. Ã tÆ°á»Ÿng thÃ¬ Ä‘Æ¡n giáº£n nhÆ°ng báº£n cháº¥t bÃ i toÃ¡n H_inf nÃ y láº¡i khÃ³ hÆ¡n nhiá»u vÃ¬ bá»™ Ä‘iá»u khiá»ƒn bá»‹ rÃ ng buá»™c vá» cáº¥u trÃºc, mÃ  ai Ä‘Ã£ tá»«ng lÃ m vá» tá»‘i Æ°u Ä‘á»u biáº¿t, cÃ ng nhiá»u rÃ ng buá»™c bÃ i toÃ¡n tá»‘i Æ°u cÃ ng cÃ ng khÃ³ giáº£i, tháº­m chÃ­ khÃ´ng kháº£ thi. Äá»ƒ giáº£i bÃ i toÃ¡n nÃ y, Pierre dÃ¹ng cÃ´ng cá»¥ non-smooth optimization vÃ  Ä‘Æ°a ra phiÃªn báº£n Ä‘áº§u tiÃªn tÃ­ch há»£p vÃ o Matlatlab Ä‘Ã¢u Ä‘Ã³ vÃ o nÄƒm 2011. Báº£n thÃ¢n mÃ¬nh cÅ©ng tá»«ng dÃ¹ng cÃ¡c cÃ´ng cá»¥ nÃ y Ä‘á»ƒ thiáº¿t káº¿ bá»™ Ä‘iá»u khiá»ƒn cho satellites hay launching vehicles, tuy nhiÃªn Ä‘á»ƒ dÃ¹ng tá»‘t cÅ©ng máº¥t khÃ¡ nhiá»u thá»i gian vÃ¬ Ä‘Ã²i kiáº¿n thá»©c cá»§a ngÆ°á»i thiáº¿t káº¿ pháº£i thá»±c sá»± hiá»ƒu sÃ¢u vá» há»‡ thá»‘ng vÃ  biáº¿t phÃ¢n tÃ­ch, thiáº¿t káº¿ há»‡ thá»‘ng Ä‘iá»u khiá»ƒn trong miá»n táº§n sá»‘.

NgÃ y nay, má»™t trong nhá»¯ng ká»· thuáº­t quan trá»ng báº­c nháº¥t liÃªn quan Ä‘áº¿n Ä‘iá»u khiá»ƒn tá»‘i Æ°u lÃ  Model Predictive Control (MPC). MPC cÆ¡ báº£n lÃ  phÆ°Æ¡ng phÃ¡p Ä‘iá»u khiá»ƒn mÃ  á»Ÿ Ä‘Ã³: giáº£i bÃ i toÃ¡n tá»‘i Æ°u trong má»™t khoáº£ng thá»i gian há»¯u háº¡n (finite horizon), apply optimal control cho bÆ°á»›c tiáº¿p theo, rá»“i láº·p láº¡i quÃ¡ trÃ¬nh nÃ y táº¡i má»—i thá»i Ä‘iá»ƒm láº¥y máº«u. Lá»‹ch sá»­ cá»§a MPC cÅ©ng tráº£i qua nhiá»u phiÃªn báº£n nhÆ°ng phiÃªn báº£n Ä‘áº§u tiÃªn Ä‘Æ°á»£c xem phÃ¡t triá»ƒn bá»Ÿi cÃ´ng ty Shell Oil, gá»i lÃ  Dynamic matrix control (DMC), tá»« nhá»¯ng nÄƒm 1970s [8]. DMC sá»­ dá»¥ng mÃ´ hÃ¬nh step response, phá»• biáº¿n trong process control Ä‘á»ƒ dá»± bÃ¡o response cá»§a process vÃ  tÃ¬m chuá»—i Ä‘iá»u khiá»ƒn tá»‘i Æ°u Ä‘á»ƒ miminize tracking error. Sau DMC, Má»—i phÆ°Æ¡ng phÃ¡p MPC khÃ¡c dÃ¹ng nhá»¯ng mÃ´ hÃ¬nh khÃ¡c nhau nhÆ° Generalized Predictive Control dÃ¹ng CARIMA, hay Transfer Function, vv. BÃ¢y giá» state-space dÆ°á»ng nhÆ° trá»Ÿ thÃ nh mÃ´ hÃ¬nh chuáº©n Ä‘á»ƒ mÃ´ hÃ¬nh hÃ³a há»‡ thá»‘ng khi thiáº¿t káº¿ MPC, nÃªn cÃ¡c version trÆ°á»›c dÆ°á»ng nhÆ° khÃ´ng ai nháº¯c Ä‘áº¿n ná»¯a.

Vá» máº·t lÃ½ thuyáº¿t, dÃ¹ MPC xuáº¥t hiá»‡n tá»« 1970s, pháº£i Ä‘áº¿n nÄƒm 2000, bÃ i bÃ¡o ná»•i tiáº¿ng cá»§a D.Q. Mayne vÃ  cá»™ng sá»± [3] má»›i giáº£i thÃ­ch Ä‘áº§y Ä‘á»§ táº¡i sao MPC worked, lÃ m rÃµ stability, performance, and feasibility cá»§a MPC. Mayne tá»•ng káº¿t cÃ¡c phiÃªn báº£n MPC vÃ  Ä‘Æ°a ra Ä‘iá»u kiá»‡n thiáº¿t káº¿ cho terminal cost vÃ  terminal constraint Ä‘á»ƒ vá»«a Ä‘áº£m báº£o recursive feasibility cho bÃ i toÃ¡n tá»‘i Æ°u trong MPC Ä‘á»“ng thá»i stability.

Trong thá»±c tiá»…n, váº¥n Ä‘á» lá»›n nháº¥t cá»§a MPC lÃ  yÃªu cáº§u tÃ­nh toÃ¡n Ä‘á»ƒ giáº£i bÃ i toÃ¡n tá»‘i Æ°u táº¡i má»—i bÆ°á»›c, vÃ¬ tháº¿ ban Ä‘áº§u chá»‰ phÃ¹ há»£p vá»›i há»‡ thá»‘ng cháº­m trong process control nhÆ° hÃ³a dáº§u. NgÃ y nay nhá» tiáº¿n bá»™ pháº§n cá»©ng vÃ  pháº§n má»m (solvers), MPC ngÃ y nay Ã¡p dá»¥ng rá»™ng rÃ£i trong há»‡ thá»‘ng nhanh nhÆ° xe hÆ¡i vÃ  robotic vehicles, má»Ÿ rá»™ng sang path/trajectory planning vÃ  cáº£ state estimation (e.g., Moving Horizon Estimation). Tá»« tháº­p niÃªn 2000, MPC phÃ¡t triá»ƒn máº¡nh máº½ vá»›i cÃ¡c nhÃ¡nh nhÆ° robust MPC, stochastic MPC, distributed MPC, vÃ  gáº§n Ä‘Ã¢y lÃ  learning-based MPC, Ä‘á»ƒ giáº£i quyáº¿t cÃ¡c váº¥n Ä‘á» phá»©c táº¡p hÆ¡n cá»§a há»‡ thá»‘ng nhÆ° model uncertainty, ...vv.
Cuá»‘i cÃ¹ng nÃ³i vá» Ä‘iá»u khiá»ƒn tá»‘i Æ°u cháº¯c cáº§n nháº¯c Ä‘áº¿n Reinforcement Learning (RL) dÃ¹ nÃ³ xuáº¥t thÃ¢n tá»« AI community. CÃ³ cÃ¢u há»i lÃ  RL cÃ³ pháº£i lÃ  má»™t phÆ°Æ¡ng phÃ¡p Ä‘iá»u khiá»ƒn tá»‘i Æ°u khÃ´ng? MÃ¬nh cho lÃ  cÃ³ vÃ¬ báº£n cháº¥t RL tÃ¬m kiáº¿m chÃ­nh sÃ¡ch (policy/control law) cho ngá» vÃ o input Ä‘á»ƒ maximize hÃ m thÆ°á»Ÿng (reward function), ráº¥t giá»‘ng vá»›i concept vá»›i Ä‘iá»u khiá»ƒn tá»‘i Æ°u. SÃ¢u hÆ¡n cÃ³ thá»ƒ chá»‰ ra tÆ°Æ¡ng quan giá»¯a RL vÃ  optimal control (vÃ­ dá»¥ nhÆ°, Bellman Equation trong RL giá»‘ng HJB trong control), nhÆ°ng mÃ¬nh chÆ°a Ä‘á»§ trÃ£i nghiá»‡m vá»›i RL Ä‘á»ƒ phÃ¢n tÃ­ch sÃ¢u hÆ¡n nÃªn xin dÃ nh láº¡i bÃ¬nh luáº­n cho nhá»¯ng ai lÃ m sÃ¢u vá» RL chia sáº» thÃªm trong lÄ©nh vá»±c nÃ y.
NhÆ° váº­y, cÃ³ thá»ƒ tháº¥y lá»‹ch sá»­ optimal control cÃ³ má»™t hÃ nh trÃ¬nh thÃº vá»‹ gáº§n má»™t tháº¿ ká»· qua. ThÃº vá»‹ hÆ¡n ngÃ y cÃ ng tháº¥y sá»± giao thoa cá»§a nÃ³ vá»›i cÃ¡c lÄ©nh vá»±c khÃ¡c vá»‹ dá»¥ RL nguá»“n gá»‘c tá»« AI. Nhá» sá»± tiáº¿n bá»™ vÆ°á»£t báº­c cá»§a mÃ¡y tÃ­nh vÃ  pháº§n má»m trong Ä‘Ã³ pháº£i ká»ƒ Ä‘áº¿n cÃ¡c solver software, viá»‡c á»©ng dá»¥ng optimal control (Ä‘áº·c biá»‡t MPC) ngÃ y cÃ ng dá»… dÃ ng hÆ¡n trong cÃ¡c há»‡ thá»‘ng thá»±c táº¿. Tuy nhiÃªn ngÃ y nay, khi sá»­ dá»¥ng solver Ä‘á»ƒ giáº£i cÃ¡c bÃ i toÃ¡n tá»‘i Æ°u má»i ngÆ°á»i cÃ³ thá»ƒ ráº¥t dá»… quÃªn má»™t lá»‹ch sá»­ Ä‘áº¹p thÃº vá»‹ cá»§a optimal control tá»« nhá»¯ng ngÃ y 1950s Ä‘áº¿n nay vÃ  tháº­m chÃ­ trÆ°á»›c Ä‘Ã³ ná»¯a.

VÃ  Ä‘á»ƒ nhá»¯ng lá»‹ch sá»­ thÃº vá»‹ Ä‘Ã³ khÃ´ng bá»‹ lÃ£ng quÃªn mÃ¬nh sáº½ ká»ƒ nÃ³ vÃ o Pháº§n 2 cá»§a topic nÃ y trong nhá»¯ng ngÃ y tiáº¿p theo, mang tÃªn "Nhá»¯ng ngÃ y trÆ°á»›c 1950s."

------------------------------------------
- [1] Kalman, R.E. (1960). Contributions to the Theory of Optimal Control.
- [2] Kalman, R.E. (1960). A New Approach to Linear Filtering and Prediction Problems.
- [3] Mayne, D.Q., et al. (2000). Constrained Model Predictive Control: Stability and Optimality, Automatica.
- [4] Doyle, J.C. (1978). Guaranteed Margins for LQG Regulators.
- [5] Doyle, J.C., et al. (1988). State-Space Solutions to Standard H2 and Hâˆ Control Problems.
- [6] Apkarian, P., et al. (2017). The Hâˆ Control Problem is Solved.
- [7] Apkarian (1994) A linear matrix inequality approach to Hâˆ control
- [8] C.R. Cutler (1980), Dynamix Matrix Control


 